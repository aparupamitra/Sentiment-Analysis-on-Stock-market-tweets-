{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Stock market tweets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source :https://github.com/nunomroliveira/stock_market_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"@user: $AAPL MOVIE. 55% return for the FEAR/G...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>@user I'd be afraid to short $AMZN - they are ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>$MNTA Over $12.00 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>$OI  Over $21.37 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>If $AAPL goes to over $451, I will go short. S...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>$MMM looks ready to break out. Looking to go l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>$AMZN - Closed over volume support inside of t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>$BBT coiled up after finding support at 50/200...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>$JCP In oscillating range, oscillators say ove...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...   \n",
       "1     2013-01-01 20:33:37  \"@user: $AAPL MOVIE. 55% return for the FEAR/G...   \n",
       "2     2013-01-01 21:43:41  @user I'd be afraid to short $AMZN - they are ...   \n",
       "3     2013-01-02 01:49:48                             $MNTA Over $12.00 URL    \n",
       "4     2013-01-02 01:51:33                              $OI  Over $21.37 URL    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  If $AAPL goes to over $451, I will go short. S...   \n",
       "4996  2013-03-31 21:37:55  $MMM looks ready to break out. Looking to go l...   \n",
       "4997  2013-03-31 22:54:02  $AMZN - Closed over volume support inside of t...   \n",
       "4998  2013-03-31 23:22:15  $BBT coiled up after finding support at 50/200...   \n",
       "4999  2013-03-31 23:35:17  $JCP In oscillating range, oscillators say ove...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock =pd.read_csv(\"stock_tweets.csv\" ,encoding='unicode_escape',error_bad_lines=False)\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    3350\n",
       "negative    1650\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bbd7e7cfc8>"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that negative class is almost 50 percent of postive class hence we shall not proceed with class balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning on text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    0\n",
       "text          0\n",
       "sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "stock.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean the text data\n",
    "# use re. sub() function which is used to replace occurrences of a particular sub-string with another sub-string.\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text =text.lower()                     # make in lower case\n",
    "    text = re.sub('\\[.*?@\\]','',text)      # remove text in square brackets\n",
    "    text =re.sub('\\n' ,'',text)\n",
    "    text = re.sub('\\w*\\d\\w*','' ,text)      # remove words containing numbers\n",
    "    text.lstrip(\"$\")                        # removes $ sign from start of string   \n",
    "    text.strip()\n",
    "    text =re.sub('[!@#$]','',text)          # replace given characters from string\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock['text'] = stock['text'].apply( lambda x:text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens= re.split('W+',text)\n",
    "    return tokens\n",
    "\n",
    "stock['tokenized_text'] =stock['text'].apply(lambda x : tokenization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    stemtext= [porter.stem(i) for i in text]\n",
    "    return stemtext\n",
    "\n",
    "stock['stemmed_text'] =stock['tokenized_text'].apply(lambda x : stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma =WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lem_text = [lemma.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "stock['lemmatized_text'] =stock['tokenized_text'].apply(lambda x : lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...  \n",
       "1     [\"user: aapl movie. % return for the fear/gree...  \n",
       "2     [user i'd be afraid to short amzn - they are l...  \n",
       "3                                    [mnta over . url ]  \n",
       "4                                     [oi  over . url ]  \n",
       "...                                                 ...  \n",
       "4995  [if aapl goes to over , i will go short. still...  \n",
       "4996  [mmm looks ready to break out. looking to go l...  \n",
       "4997  [amzn - closed over volume support inside of t...  \n",
       "4998  [bbt coiled up after finding support at / sma'...  \n",
       "4999  [jcp in oscillating range, oscillators say ove...  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stp words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whereupon', 'n‘t', 'whoever', 'ca', 'serious', 'seemed', 'been', 'few', 'which', 'there', 'myself', 'part', 'seeming', 'indeed', 'call', 'another', 'namely', 'show', 'used', 'for', 'sometime', 'wherever', 'bottom', 'ever', 'fifteen', 'ten', 'top', 'done', 'noone', 'not', 'yourself', 'beyond', 'afterwards', 'move', 'more', 'most', 'therein', 'back', \"'ve\", 'my', 'himself', '‘ll', 'any', 'perhaps', 'something', 'last', 'until', 'anyhow', 'nobody', 'our', 'hereby', 're', 'hers', 'does', 'put', 'every', 'into', 'such', 'they', 'everywhere', 'one', 'always', 'has', 'full', 'anyway', 'third', 'us', 'it', 'towards', 'almost', 'on', 'out', 'her', 'as', 'might', 'same', 'your', 'me', 'hundred', 'together', 'the', 'already', 'an', 'eight', 'mostly', 'have', 'further', 'only', 'using', 'what', 'whereas', 'though', 'name', 'being', 'became', 'regarding', 'side', 'moreover', 'under', 'did', 'whether', 'amongst', 'that', 'whence', 'when', 'we', 'empty', 'well', 'herself', 'eleven', 'whither', 'say', 'him', 'even', 'off', 'against', 'give', 'below', 'beforehand', 'really', \"'ll\", 'itself', 'made', 'thus', 'toward', 'his', '‘d', 'you', 'get', 'whole', 'a', 'would', 'ours', 'becomes', 'nevertheless', 'many', 'unless', 'throughout', 'either', 'over', 'these', 'and', 'so', 'them', '’ll', 'those', 'since', 'somehow', '’re', 'alone', 'neither', 'without', 'forty', 'cannot', 'make', 'he', 'twelve', 'front', 'in', 'none', 'down', 'after', 'was', 'thereupon', 'keep', 'around', 'go', 'however', 'no', 'becoming', 'yourselves', 'else', 'just', 'between', 'yet', 'whereby', '’m', 'others', 'who', 'former', 'had', 'amount', 'among', 'everyone', 'herein', 'two', 'nor', 'other', 'could', 'thereafter', 'still', 'thereby', 'anyone', 'because', 'before', 'rather', 'will', 'hereafter', 'latterly', '‘m', 'how', 'may', 'three', 'across', 'do', \"'m\", 'become', 'whom', 'up', 'along', 'each', 'due', 'sometimes', 'anything', 'within', 'is', 'several', 'should', 'latter', 'themselves', 'are', 'by', 'whereafter', 'she', 'someone', 'nothing', 'nowhere', 'behind', 'or', 'too', 'twenty', 'wherein', 'be', 'except', 'once', 'enough', 'besides', 'first', 'am', \"'s\", 'quite', 'anywhere', 'from', 'can', 'about', 'onto', '’s', 'this', 'then', 'than', 'all', 'ourselves', 'at', 'while', 'also', '‘re', 'if', 'five', 'upon', 'yours', 'least', 'very', 'although', 'where', 'less', 'above', 'nine', 'much', '’d', 'hence', 'of', '‘ve', 'whose', '’ve', 'meanwhile', 'see', 'doing', 'per', 'elsewhere', 'their', 'mine', 'whatever', 'via', 'to', 'were', 'some', 'thence', 'various', '‘s', 'here', 'why', 'please', 'thru', 'through', 'seems', 'take', 'again', 'during', 'seem', 'six', \"n't\", 'formerly', 'sixty', \"'re\", 'four', 'n’t', 'but', 'everything', 'whenever', \"'d\", 'often', 'never', 'with', 'next', 'hereupon', 'otherwise', 'i', 'somewhere', 'both', 'beside', 'fifty', 'therefore', 'its', 'now', 'own', 'must'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords[0:300]=['whereupon', 'n‘t', 'whoever', 'ca', 'serious', 'seemed', 'been', 'few', 'which', 'there', 'myself', 'part', 'seeming', 'indeed', 'call', 'another', 'namely', 'show', 'used', 'for', 'sometime', 'wherever', 'bottom', 'ever', 'fifteen', 'ten', 'top', 'done', 'noone', 'not', 'yourself', 'beyond', 'afterwards', 'move', 'more', 'most', 'therein', 'back', \"'ve\", 'my', 'himself', '‘ll', 'any', 'perhaps', 'something', 'last', 'until', 'anyhow', 'nobody', 'our', 'hereby', 're', 'hers', 'does', 'put', 'every', 'into', 'such', 'they', 'everywhere', 'one', 'always', 'has', 'full', 'anyway', 'third', 'us', 'it', 'towards', 'almost', 'on', 'out', 'her', 'as', 'might', 'same', 'your', 'me', 'hundred', 'together', 'the', 'already', 'an', 'eight', 'mostly', 'have', 'further', 'only', 'using', 'what', 'whereas', 'though', 'name', 'being', 'became', 'regarding', 'side', 'moreover', 'under', 'did', 'whether', 'amongst', 'that', 'whence', 'when', 'we', 'empty', 'well', 'herself', 'eleven', 'whither', 'say', 'him', 'even', 'off', 'against', 'give', 'below', 'beforehand', 'really', \"'ll\", 'itself', 'made', 'thus', 'toward', 'his', '‘d', 'you', 'get', 'whole', 'a', 'would', 'ours', 'becomes', 'nevertheless', 'many', 'unless', 'throughout', 'either', 'over', 'these', 'and', 'so', 'them', '’ll', 'those', 'since', 'somehow', '’re', 'alone', 'neither', 'without', 'forty', 'cannot', 'make', 'he', 'twelve', 'front', 'in', 'none', 'down', 'after', 'was', 'thereupon', 'keep', 'around', 'go', 'however', 'no', 'becoming', 'yourselves', 'else', 'just', 'between', 'yet', 'whereby', '’m', 'others', 'who', 'former', 'had', 'amount', 'among', 'everyone', 'herein', 'two', 'nor', 'other', 'could', 'thereafter', 'still', 'thereby', 'anyone', 'because', 'before', 'rather', 'will', 'hereafter', 'latterly', '‘m', 'how', 'may', 'three', 'across', 'do', \"'m\", 'become', 'whom', 'up', 'along', 'each', 'due', 'sometimes', 'anything', 'within', 'is', 'several', 'should', 'latter', 'themselves', 'are', 'by', 'whereafter', 'she', 'someone', 'nothing', 'nowhere', 'behind', 'or', 'too', 'twenty', 'wherein', 'be', 'except', 'once', 'enough', 'besides', 'first', 'am', \"'s\", 'quite', 'anywhere', 'from', 'can', 'about', 'onto', '’s', 'this', 'then', 'than', 'all', 'ourselves', 'at', 'while', 'also', '‘re', 'if', 'five', 'upon', 'yours', 'least', 'very', 'although', 'where', 'less', 'above', 'nine', 'much', '’d', 'hence', 'of', '‘ve', 'whose', '’ve', 'meanwhile', 'see', 'doing', 'per', 'elsewhere', 'their', 'mine', 'whatever', 'via', 'to', 'were', 'some', 'thence', 'various', '‘s', 'here', 'why', 'please', 'thru', 'through', 'seems', 'take', 'again', 'during', 'seem', 'six', \"n't\", 'formerly', 'sixty', \"'re\", 'four', 'n’t', 'but', 'everything', 'whenever', \"'d\", 'often', 'never', 'with', 'next', 'hereupon', 'otherwise', 'i', 'somewhere', 'both', 'beside', 'fifty', 'therefore', 'its', 'now', 'own', 'must']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whereupon',\n",
       " 'n‘t',\n",
       " 'whoever',\n",
       " 'ca',\n",
       " 'serious',\n",
       " 'seemed',\n",
       " 'been',\n",
       " 'few',\n",
       " 'which',\n",
       " 'there',\n",
       " 'myself',\n",
       " 'part',\n",
       " 'seeming',\n",
       " 'indeed',\n",
       " 'call',\n",
       " 'another',\n",
       " 'namely',\n",
       " 'show',\n",
       " 'used',\n",
       " 'for',\n",
       " 'sometime',\n",
       " 'wherever',\n",
       " 'bottom',\n",
       " 'ever',\n",
       " 'fifteen',\n",
       " 'ten',\n",
       " 'top',\n",
       " 'done',\n",
       " 'noone',\n",
       " 'not',\n",
       " 'yourself',\n",
       " 'beyond',\n",
       " 'afterwards',\n",
       " 'move',\n",
       " 'more',\n",
       " 'most',\n",
       " 'therein',\n",
       " 'back',\n",
       " \"'ve\",\n",
       " 'my',\n",
       " 'himself',\n",
       " '‘ll',\n",
       " 'any',\n",
       " 'perhaps',\n",
       " 'something',\n",
       " 'last',\n",
       " 'until',\n",
       " 'anyhow',\n",
       " 'nobody',\n",
       " 'our',\n",
       " 'hereby',\n",
       " 're',\n",
       " 'hers',\n",
       " 'does',\n",
       " 'put',\n",
       " 'every',\n",
       " 'into',\n",
       " 'such',\n",
       " 'they',\n",
       " 'everywhere',\n",
       " 'one',\n",
       " 'always',\n",
       " 'has',\n",
       " 'full',\n",
       " 'anyway',\n",
       " 'third',\n",
       " 'us',\n",
       " 'it',\n",
       " 'towards',\n",
       " 'almost',\n",
       " 'on',\n",
       " 'out',\n",
       " 'her',\n",
       " 'as',\n",
       " 'might',\n",
       " 'same',\n",
       " 'your',\n",
       " 'me',\n",
       " 'hundred',\n",
       " 'together',\n",
       " 'the',\n",
       " 'already',\n",
       " 'an',\n",
       " 'eight',\n",
       " 'mostly',\n",
       " 'have',\n",
       " 'further',\n",
       " 'only',\n",
       " 'using',\n",
       " 'what',\n",
       " 'whereas',\n",
       " 'though',\n",
       " 'name',\n",
       " 'being',\n",
       " 'became',\n",
       " 'regarding',\n",
       " 'side',\n",
       " 'moreover',\n",
       " 'under',\n",
       " 'did',\n",
       " 'whether',\n",
       " 'amongst',\n",
       " 'that',\n",
       " 'whence',\n",
       " 'when',\n",
       " 'we',\n",
       " 'empty',\n",
       " 'well',\n",
       " 'herself',\n",
       " 'eleven',\n",
       " 'whither',\n",
       " 'say',\n",
       " 'him',\n",
       " 'even',\n",
       " 'off',\n",
       " 'against',\n",
       " 'give',\n",
       " 'below',\n",
       " 'beforehand',\n",
       " 'really',\n",
       " \"'ll\",\n",
       " 'itself',\n",
       " 'made',\n",
       " 'thus',\n",
       " 'toward',\n",
       " 'his',\n",
       " '‘d',\n",
       " 'you',\n",
       " 'get',\n",
       " 'whole',\n",
       " 'a',\n",
       " 'would',\n",
       " 'ours',\n",
       " 'becomes',\n",
       " 'nevertheless',\n",
       " 'many',\n",
       " 'unless',\n",
       " 'throughout',\n",
       " 'either',\n",
       " 'over',\n",
       " 'these',\n",
       " 'and',\n",
       " 'so',\n",
       " 'them',\n",
       " '’ll',\n",
       " 'those',\n",
       " 'since',\n",
       " 'somehow',\n",
       " '’re',\n",
       " 'alone',\n",
       " 'neither',\n",
       " 'without',\n",
       " 'forty',\n",
       " 'cannot',\n",
       " 'make',\n",
       " 'he',\n",
       " 'twelve',\n",
       " 'front',\n",
       " 'in',\n",
       " 'none',\n",
       " 'down',\n",
       " 'after',\n",
       " 'was',\n",
       " 'thereupon',\n",
       " 'keep',\n",
       " 'around',\n",
       " 'go',\n",
       " 'however',\n",
       " 'no',\n",
       " 'becoming',\n",
       " 'yourselves',\n",
       " 'else',\n",
       " 'just',\n",
       " 'between',\n",
       " 'yet',\n",
       " 'whereby',\n",
       " '’m',\n",
       " 'others',\n",
       " 'who',\n",
       " 'former',\n",
       " 'had',\n",
       " 'amount',\n",
       " 'among',\n",
       " 'everyone',\n",
       " 'herein',\n",
       " 'two',\n",
       " 'nor',\n",
       " 'other',\n",
       " 'could',\n",
       " 'thereafter',\n",
       " 'still',\n",
       " 'thereby',\n",
       " 'anyone',\n",
       " 'because',\n",
       " 'before',\n",
       " 'rather',\n",
       " 'will',\n",
       " 'hereafter',\n",
       " 'latterly',\n",
       " '‘m',\n",
       " 'how',\n",
       " 'may',\n",
       " 'three',\n",
       " 'across',\n",
       " 'do',\n",
       " \"'m\",\n",
       " 'become',\n",
       " 'whom',\n",
       " 'up',\n",
       " 'along',\n",
       " 'each',\n",
       " 'due',\n",
       " 'sometimes',\n",
       " 'anything',\n",
       " 'within',\n",
       " 'is',\n",
       " 'several',\n",
       " 'should',\n",
       " 'latter',\n",
       " 'themselves',\n",
       " 'are',\n",
       " 'by',\n",
       " 'whereafter',\n",
       " 'she',\n",
       " 'someone',\n",
       " 'nothing',\n",
       " 'nowhere',\n",
       " 'behind',\n",
       " 'or',\n",
       " 'too',\n",
       " 'twenty',\n",
       " 'wherein',\n",
       " 'be',\n",
       " 'except',\n",
       " 'once',\n",
       " 'enough',\n",
       " 'besides',\n",
       " 'first',\n",
       " 'am',\n",
       " \"'s\",\n",
       " 'quite',\n",
       " 'anywhere',\n",
       " 'from',\n",
       " 'can',\n",
       " 'about',\n",
       " 'onto',\n",
       " '’s',\n",
       " 'this',\n",
       " 'then',\n",
       " 'than',\n",
       " 'all',\n",
       " 'ourselves',\n",
       " 'at',\n",
       " 'while',\n",
       " 'also',\n",
       " '‘re',\n",
       " 'if',\n",
       " 'five',\n",
       " 'upon',\n",
       " 'yours',\n",
       " 'least',\n",
       " 'very',\n",
       " 'although',\n",
       " 'where',\n",
       " 'less',\n",
       " 'above',\n",
       " 'nine',\n",
       " 'much',\n",
       " '’d',\n",
       " 'hence',\n",
       " 'of',\n",
       " '‘ve',\n",
       " 'whose',\n",
       " '’ve',\n",
       " 'meanwhile',\n",
       " 'see',\n",
       " 'doing',\n",
       " 'per',\n",
       " 'elsewhere',\n",
       " 'their',\n",
       " 'mine',\n",
       " 'whatever',\n",
       " 'via',\n",
       " 'to',\n",
       " 'were',\n",
       " 'some',\n",
       " 'thence',\n",
       " 'various',\n",
       " '‘s',\n",
       " 'here',\n",
       " 'why',\n",
       " 'please',\n",
       " 'thru',\n",
       " 'through',\n",
       " 'seems',\n",
       " 'take',\n",
       " 'again',\n",
       " 'during',\n",
       " 'seem',\n",
       " 'six',\n",
       " \"n't\",\n",
       " 'formerly',\n",
       " 'sixty',\n",
       " \"'re\",\n",
       " 'four',\n",
       " 'n’t',\n",
       " 'but',\n",
       " 'everything',\n",
       " 'whenever',\n",
       " \"'d\",\n",
       " 'often',\n",
       " 'never',\n",
       " 'with',\n",
       " 'next',\n",
       " 'hereupon',\n",
       " 'otherwise',\n",
       " 'i',\n",
       " 'somewhere',\n",
       " 'both',\n",
       " 'beside',\n",
       " 'fifty',\n",
       " 'therefore',\n",
       " 'its',\n",
       " 'now',\n",
       " 'own',\n",
       " 'must']"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(text):\n",
    "    removed_stopwords=[ i for i in text if i not in stopwords]\n",
    "    return removed_stopwords\n",
    "    \n",
    "stock['final_cleaned_text'] =stock['lemmatized_text'].apply(lambda x : stopword_removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                     final_cleaned_text  \n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...  \n",
       "1     [\"user: aapl movie. % return for the fear/gree...  \n",
       "2     [user i'd be afraid to short amzn - they are l...  \n",
       "3                                    [mnta over . url ]  \n",
       "4                                     [oi  over . url ]  \n",
       "...                                                 ...  \n",
       "4995  [if aapl goes to over , i will go short. still...  \n",
       "4996  [mmm looks ready to break out. looking to go l...  \n",
       "4997  [amzn - closed over volume support inside of t...  \n",
       "4998  [bbt coiled up after finding support at / sma'...  \n",
       "4999  [jcp in oscillating range, oscillators say ove...  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our final cleaned text is stock['final_cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Perform VADER (valence aware dictionary for sentiment reasoning) model for Sentiment Analysis on stock price twitter reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is a model that is used for sentiment analysis and is sensitive to polarity (positive /negative).\n",
    "It maps the lexical features to emotional intensities called sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid=SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any one review and check its score\n",
    "\n",
    "\n",
    "review1 = stock.iloc[2]['sentiment']\n",
    "review1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will now  calculate scores and compound scores for entire dataset by creating seperate columns and will compare our predictions with the given results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for adding sentiment scores \n",
    "\n",
    "stock['scores']= stock['sentiment'].apply(lambda review:sid.polarity_scores(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for adding compound scores \n",
    "\n",
    "stock['compound_score']=stock['scores'].apply(lambda dic:dic['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create condition on compound score to predict sentiment\n",
    "\n",
    "stock['predicted_sentiment'] =stock['compound_score'].apply(lambda x :'positive' if x>=0 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                     final_cleaned_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                                 scores  compound_score  \\\n",
       "0     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "1     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "2     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "3     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "...                                                 ...             ...   \n",
       "4995  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...         -0.5719   \n",
       "4996  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4997  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4998  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4999  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0               positive  \n",
       "1               positive  \n",
       "2               positive  \n",
       "3               positive  \n",
       "4               positive  \n",
       "...                  ...  \n",
       "4995            negative  \n",
       "4996            positive  \n",
       "4997            positive  \n",
       "4998            positive  \n",
       "4999            positive  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# compare given label with our predicted sentiment value\n",
    "\n",
    "print(accuracy_score(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 =accuracy_score(stock['sentiment'] ,stock['predicted_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00      1650\n",
      "    positive       1.00      1.00      1.00      3350\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1650    0]\n",
      " [   0 3350]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using different machine language algorithm we will try to predict sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=stock['final_cleaned_text']\n",
    "y=stock['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since stock['final_cleaned_text'] is in array of array , we need to convert into array of strings\n",
    "\n",
    "stock['final_cleaned_text']=[\" \".join(i) for i in stock['final_cleaned_text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test ,y_train,y_test =train_test_split(x,y,test_size=0.25 ,random_state=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3305      come fly with me, let?s fly, let?s fly away  al\n",
       "4579    citi reiterates sell on bbry & tp of  - \"shock...\n",
       "1662                 has anyone shorted kerx? what price?\n",
       "2851    faz about to explode, get ready, bac just brok...\n",
       "192     gs jpm xlf hod, they are hungry for stocks out...\n",
       "                              ...                        \n",
       "3603     aapl strong if they keep buying into the close..\n",
       "4722    ma url major bearish divergence(now confirmed ...\n",
       "3340    stalking. rising channel on flir. if a pullbac...\n",
       "3064    xco . has technical support  min downside with...\n",
       "3398    amzn goog and crm move higher as the nq_f turn...\n",
       "Name: final_cleaned_text, Length: 3750, dtype: object"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4088    hca entering long, here's the daily, like the ...\n",
       "2080                             rjet entry . stop . url \n",
       "41      x out the / due to the move today and the kirb...\n",
       "796     red monthly triangle on cytx,....net profit  ,...\n",
       "354                                           mon - added\n",
       "                              ...                        \n",
       "2952    dakt short . /  break, ideal flat/trendless/re...\n",
       "757                     ampe,...sell short at .,  scaling\n",
       "3907                   cspi buying in new nano cap folio.\n",
       "1251    aapl head and shoulders pattern plays out, one...\n",
       "4188    f really looking good here, great call option ...\n",
       "Name: final_cleaned_text, Length: 1250, dtype: object"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a)  Use linear support vector machine along with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings(Inverse Document Frequency (IDF) is a weight indicating how commonly a word is used.The more frequent its usage across documents, the lower its score), and allow you to encode new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('Svm',LinearSVC())])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 =pipeline.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2 =accuracy_score(y_test,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.59      0.67       421\n",
      "    positive       0.81      0.90      0.86       829\n",
      "\n",
      "    accuracy                           0.80      1250\n",
      "   macro avg       0.79      0.75      0.76      1250\n",
      "weighted avg       0.80      0.80      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b) Using Logistic regression and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('logisticregression',LogisticRegression(penalty ='l2',solver ='saga'))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 =pipeline.predict(x_test)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3 =accuracy_score(y_test,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.44      0.57       421\n",
      "    positive       0.77      0.95      0.85       829\n",
      "\n",
      "    accuracy                           0.78      1250\n",
      "   macro avg       0.80      0.70      0.71      1250\n",
      "weighted avg       0.79      0.78      0.76      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c) Using Naive Bayes and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('naivebayes',MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3 =pipeline.predict(x_test)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4= accuracy_score(y_test,predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.21      0.34       421\n",
      "    positive       0.71      0.99      0.83       829\n",
      "\n",
      "    accuracy                           0.73      1250\n",
      "   macro avg       0.82      0.60      0.58      1250\n",
      "weighted avg       0.79      0.73      0.66      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d) Using Stochastic Gradiant Descent and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('SGD',SGDClassifier(loss = 'hinge', penalty = 'l2', random_state=0))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict4 =pipeline.predict(x_test)\n",
    "predict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy5= accuracy_score(y_test,predict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.61      0.66       421\n",
      "    positive       0.82      0.89      0.85       829\n",
      "\n",
      "    accuracy                           0.79      1250\n",
      "   macro avg       0.78      0.75      0.76      1250\n",
      "weighted avg       0.79      0.79      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e) Using Random Forest classifier and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('RFC', RandomForestClassifier(min_samples_split=4))])"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('RFC',RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,min_samples_split=4))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit =pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict5 =pipeline.predict(x_test)\n",
    "predict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy6= accuracy_score(y_test,predict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.54      0.66       421\n",
      "    positive       0.80      0.94      0.87       829\n",
      "\n",
      "    accuracy                           0.81      1250\n",
      "   macro avg       0.81      0.74      0.76      1250\n",
      "weighted avg       0.81      0.81      0.80      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performances of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD classifier</td>\n",
       "      <td>0.7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0                   VADER    1.0000\n",
       "1               LinearSVM    0.7992\n",
       "2     Logistic Regression    0.7792\n",
       "3             Naive Bayes    0.7280\n",
       "4          SGD classifier    0.7936\n",
       "5  RandomForestClassifier    0.8080"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies =[accuracy1 ,accuracy2,accuracy3 ,accuracy4,accuracy5,accuracy6]\n",
    "models =['VADER','LinearSVM','Logistic Regression','Naive Bayes','SGD classifier','RandomForestClassifier']\n",
    "\n",
    "df =pd.DataFrame( {'Model':models ,'Accuracy': all_accuracies })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see RandomForest Classifier gives teh best result although SVM and SGD also gives nearly same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
