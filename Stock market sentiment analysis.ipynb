{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Stock market tweets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source :https://github.com/nunomroliveira/stock_market_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"@user: $AAPL MOVIE. 55% return for the FEAR/G...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>@user I'd be afraid to short $AMZN - they are ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>$MNTA Over $12.00 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>$OI  Over $21.37 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>If $AAPL goes to over $451, I will go short. S...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>$MMM looks ready to break out. Looking to go l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>$AMZN - Closed over volume support inside of t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>$BBT coiled up after finding support at 50/200...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>$JCP In oscillating range, oscillators say ove...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...   \n",
       "1     2013-01-01 20:33:37  \"@user: $AAPL MOVIE. 55% return for the FEAR/G...   \n",
       "2     2013-01-01 21:43:41  @user I'd be afraid to short $AMZN - they are ...   \n",
       "3     2013-01-02 01:49:48                             $MNTA Over $12.00 URL    \n",
       "4     2013-01-02 01:51:33                              $OI  Over $21.37 URL    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  If $AAPL goes to over $451, I will go short. S...   \n",
       "4996  2013-03-31 21:37:55  $MMM looks ready to break out. Looking to go l...   \n",
       "4997  2013-03-31 22:54:02  $AMZN - Closed over volume support inside of t...   \n",
       "4998  2013-03-31 23:22:15  $BBT coiled up after finding support at 50/200...   \n",
       "4999  2013-03-31 23:35:17  $JCP In oscillating range, oscillators say ove...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock =pd.read_csv(\"stock_tweets.csv\" ,encoding='unicode_escape',error_bad_lines=False)\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    3350\n",
       "negative    1650\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x200c19f85c8>"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that negative class is almost 50 percent of postive class hence we shall not proceed with class balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see the similarity between any two texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = stock.iloc[2]['text']\n",
    "review1 =nlp(review1)\n",
    "\n",
    "review2 = stock.iloc[4]['text']\n",
    "review2 =nlp(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user I'd be afraid to short $AMZN - they are looking like a near-monopoly in eBooks and infrastructure-as-a-service\n",
      "$OI  Over $21.37 URL \n"
     ]
    }
   ],
   "source": [
    "print(review1)\n",
    "print(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reviews(text1 ,text2):\n",
    "    for i in text1:\n",
    "        for j in text2:\n",
    "            print(f\"{i.text:{10}} {j.text:{10}} {i.similarity(j)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user      $          -0.040974605828523636\n",
      "@user      OI         0.10025622695684433\n",
      "@user                 0.0\n",
      "@user      Over       -0.24740222096443176\n",
      "@user      $          -0.040974605828523636\n",
      "@user      21.37      0.17304401099681854\n",
      "@user      URL        0.08888249844312668\n",
      "I          $          0.0425683856010437\n",
      "I          OI         0.2929275631904602\n",
      "I                     0.0\n",
      "I          Over       0.31890296936035156\n",
      "I          $          0.0425683856010437\n",
      "I          21.37      -0.19259053468704224\n",
      "I          URL        0.2791401743888855\n",
      "'d         $          0.17285074293613434\n",
      "'d         OI         0.09736473858356476\n",
      "'d                    0.0\n",
      "'d         Over       0.4672309458255768\n",
      "'d         $          0.17285074293613434\n",
      "'d         21.37      -0.2872776985168457\n",
      "'d         URL        0.15386636555194855\n",
      "be         $          0.1695544570684433\n",
      "be         OI         0.06755942106246948\n",
      "be                    0.0\n",
      "be         Over       0.4745045602321625\n",
      "be         $          0.1695544570684433\n",
      "be         21.37      -0.2699706554412842\n",
      "be         URL        0.2083832174539566\n",
      "afraid     $          -0.014134563505649567\n",
      "afraid     OI         0.12015127390623093\n",
      "afraid                0.0\n",
      "afraid     Over       0.34436264634132385\n",
      "afraid     $          -0.014134563505649567\n",
      "afraid     21.37      -0.22323918342590332\n",
      "afraid     URL        0.14298194646835327\n",
      "to         $          0.20387788116931915\n",
      "to         OI         0.03685293346643448\n",
      "to                    0.0\n",
      "to         Over       0.5356765985488892\n",
      "to         $          0.20387788116931915\n",
      "to         21.37      -0.2247336357831955\n",
      "to         URL        0.2146589756011963\n",
      "short      $          0.14246179163455963\n",
      "short      OI         0.01614736206829548\n",
      "short                 0.0\n",
      "short      Over       0.40762048959732056\n",
      "short      $          0.14246179163455963\n",
      "short      21.37      -0.19707165658473969\n",
      "short      URL        0.2315237820148468\n",
      "$          $          1.0\n",
      "$          OI         -0.018495209515094757\n",
      "$                     0.0\n",
      "$          Over       0.25578024983406067\n",
      "$          $          1.0\n",
      "$          21.37      0.14403726160526276\n",
      "$          URL        0.06995110958814621\n",
      "AMZN       $          0.037851765751838684\n",
      "AMZN       OI         0.10242702066898346\n",
      "AMZN                  0.0\n",
      "AMZN       Over       -0.21591302752494812\n",
      "AMZN       $          0.037851765751838684\n",
      "AMZN       21.37      0.20950902998447418\n",
      "AMZN       URL        0.044967226684093475\n",
      "-          $          0.25122904777526855\n",
      "-          OI         0.02201727218925953\n",
      "-                     0.0\n",
      "-          Over       0.10074940323829651\n",
      "-          $          0.25122904777526855\n",
      "-          21.37      -0.09504158794879913\n",
      "-          URL        0.07424484193325043\n",
      "they       $          0.10776302218437195\n",
      "they       OI         0.10729813575744629\n",
      "they                  0.0\n",
      "they       Over       0.5504165291786194\n",
      "they       $          0.10776302218437195\n",
      "they       21.37      -0.3388083577156067\n",
      "they       URL        0.19804605841636658\n",
      "are        $          0.0893348902463913\n",
      "are        OI         0.03389918431639671\n",
      "are                   0.0\n",
      "are        Over       0.3973138928413391\n",
      "are        $          0.0893348902463913\n",
      "are        21.37      -0.26103487610816956\n",
      "are        URL        0.17048341035842896\n",
      "looking    $          0.118894562125206\n",
      "looking    OI         0.015501972287893295\n",
      "looking               0.0\n",
      "looking    Over       0.4395284354686737\n",
      "looking    $          0.118894562125206\n",
      "looking    21.37      -0.29672667384147644\n",
      "looking    URL        0.23746231198310852\n",
      "like       $          0.11461963504552841\n",
      "like       OI         0.08667252957820892\n",
      "like                  0.0\n",
      "like       Over       0.5306462645530701\n",
      "like       $          0.11461963504552841\n",
      "like       21.37      -0.3539392352104187\n",
      "like       URL        0.22256341576576233\n",
      "a          $          0.18682853877544403\n",
      "a          OI         -0.014674847945570946\n",
      "a                     0.0\n",
      "a          Over       0.4591664969921112\n",
      "a          $          0.18682853877544403\n",
      "a          21.37      -0.20056574046611786\n",
      "a          URL        0.16702522337436676\n",
      "near       $          0.07030881196260452\n",
      "near       OI         -0.012104055844247341\n",
      "near                  0.0\n",
      "near       Over       0.3573305904865265\n",
      "near       $          0.07030881196260452\n",
      "near       21.37      -0.12097101658582687\n",
      "near       URL        0.07899398356676102\n",
      "-          $          0.25122904777526855\n",
      "-          OI         0.02201727218925953\n",
      "-                     0.0\n",
      "-          Over       0.10074940323829651\n",
      "-          $          0.25122904777526855\n",
      "-          21.37      -0.09504158794879913\n",
      "-          URL        0.07424484193325043\n",
      "monopoly   $          0.035302430391311646\n",
      "monopoly   OI         0.17565417289733887\n",
      "monopoly              0.0\n",
      "monopoly   Over       0.19287705421447754\n",
      "monopoly   $          0.035302430391311646\n",
      "monopoly   21.37      -0.11524231731891632\n",
      "monopoly   URL        0.11009345203638077\n",
      "in         $          0.10867702960968018\n",
      "in         OI         -0.011914561502635479\n",
      "in                    0.0\n",
      "in         Over       0.518490195274353\n",
      "in         $          0.10867702960968018\n",
      "in         21.37      -0.1744030863046646\n",
      "in         URL        0.1459735482931137\n",
      "eBooks     $          0.09660249203443527\n",
      "eBooks     OI         0.016670627519488335\n",
      "eBooks                0.0\n",
      "eBooks     Over       0.1616746187210083\n",
      "eBooks     $          0.09660249203443527\n",
      "eBooks     21.37      0.02403656207025051\n",
      "eBooks     URL        0.2668120861053467\n",
      "and        $          0.0878458097577095\n",
      "and        OI         -0.02479935996234417\n",
      "and                   0.0\n",
      "and        Over       0.5485153198242188\n",
      "and        $          0.0878458097577095\n",
      "and        21.37      -0.2861573100090027\n",
      "and        URL        0.14781169593334198\n",
      "infrastructure $          0.09668101370334625\n",
      "infrastructure OI         -0.03346571326255798\n",
      "infrastructure            0.0\n",
      "infrastructure Over       0.3073303699493408\n",
      "infrastructure $          0.09668101370334625\n",
      "infrastructure 21.37      -0.15915648639202118\n",
      "infrastructure URL        0.018133390694856644\n",
      "-          $          0.25122904777526855\n",
      "-          OI         0.02201727218925953\n",
      "-                     0.0\n",
      "-          Over       0.10074940323829651\n",
      "-          $          0.25122904777526855\n",
      "-          21.37      -0.09504158794879913\n",
      "-          URL        0.07424484193325043\n",
      "as         $          0.17430178821086884\n",
      "as         OI         0.04819926619529724\n",
      "as                    0.0\n",
      "as         Over       0.525879979133606\n",
      "as         $          0.17430178821086884\n",
      "as         21.37      -0.163481205701828\n",
      "as         URL        0.19862253963947296\n",
      "-          $          0.25122904777526855\n",
      "-          OI         0.02201727218925953\n",
      "-                     0.0\n",
      "-          Over       0.10074940323829651\n",
      "-          $          0.25122904777526855\n",
      "-          21.37      -0.09504158794879913\n",
      "-          URL        0.07424484193325043\n",
      "a          $          0.18682853877544403\n",
      "a          OI         -0.014674847945570946\n",
      "a                     0.0\n",
      "a          Over       0.4591664969921112\n",
      "a          $          0.18682853877544403\n",
      "a          21.37      -0.20056574046611786\n",
      "a          URL        0.16702522337436676\n",
      "-          $          0.25122904777526855\n",
      "-          OI         0.02201727218925953\n",
      "-                     0.0\n",
      "-          Over       0.10074940323829651\n",
      "-          $          0.25122904777526855\n",
      "-          21.37      -0.09504158794879913\n",
      "-          URL        0.07424484193325043\n",
      "service    $          0.14194993674755096\n",
      "service    OI         0.006504947319626808\n",
      "service               0.0\n",
      "service    Over       0.33327481150627136\n",
      "service    $          0.14194993674755096\n",
      "service    21.37      -0.2435171753168106\n",
      "service    URL        0.21641889214515686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aparu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "compare_reviews(review1 ,review2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of speech tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_speech(text1):\n",
    "    for i in text1:\n",
    "        print(f\"{i.text:{10}} {i.tag_:{10}} {spacy.explain(i.tag_)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user      WP         wh-pronoun, personal \n",
      "I          PRP        pronoun, personal \n",
      "'d         MD         verb, modal auxiliary \n",
      "be         VB         verb, base form \n",
      "afraid     JJ         adjective \n",
      "to         TO         infinitival \"to\" \n",
      "short      VB         verb, base form \n",
      "$          $          symbol, currency \n",
      "AMZN       NNP        noun, proper singular \n",
      "-          :          punctuation mark, colon or ellipsis \n",
      "they       PRP        pronoun, personal \n",
      "are        VBP        verb, non-3rd person singular present \n",
      "looking    VBG        verb, gerund or present participle \n",
      "like       IN         conjunction, subordinating or preposition \n",
      "a          DT         determiner \n",
      "near       JJ         adjective \n",
      "-          HYPH       punctuation mark, hyphen \n",
      "monopoly   NN         noun, singular or mass \n",
      "in         IN         conjunction, subordinating or preposition \n",
      "eBooks     NNS        noun, plural \n",
      "and        CC         conjunction, coordinating \n",
      "infrastructure NN         noun, singular or mass \n",
      "-          HYPH       punctuation mark, hyphen \n",
      "as         IN         conjunction, subordinating or preposition \n",
      "-          HYPH       punctuation mark, hyphen \n",
      "a          DT         determiner \n",
      "-          HYPH       punctuation mark, hyphen \n",
      "service    NN         noun, singular or mass \n"
     ]
    }
   ],
   "source": [
    "part_of_speech(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning on text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    0\n",
       "text          0\n",
       "sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "stock.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean the text data\n",
    "# use re. sub() function which is used to replace occurrences of a particular sub-string with another sub-string.\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text =text.lower()                     # make in lower case\n",
    "    text = re.sub('\\[.*?@\\]','',text)      # remove text in square brackets\n",
    "    text =re.sub('\\n' ,'',text)\n",
    "    text = re.sub('\\w*\\d\\w*','' ,text)      # remove words containing numbers\n",
    "    text.lstrip(\"$\")                        # removes $ sign from start of string   \n",
    "    text.strip()\n",
    "    text =re.sub('[!@#$]','',text)          # replace given characters from string\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock['text'] = stock['text'].apply( lambda x:text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens= re.split('W+',text)\n",
    "    return tokens\n",
    "\n",
    "stock['tokenized_text'] =stock['text'].apply(lambda x : tokenization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    stemtext= [porter.stem(i) for i in text]\n",
    "    return stemtext\n",
    "\n",
    "stock['stemmed_text'] =stock['tokenized_text'].apply(lambda x : stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma =WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lem_text = [lemma.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "stock['lemmatized_text'] =stock['tokenized_text'].apply(lambda x : lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...  \n",
       "1     [\"user: aapl movie. % return for the fear/gree...  \n",
       "2     [user i'd be afraid to short amzn - they are l...  \n",
       "3                                    [mnta over . url ]  \n",
       "4                                     [oi  over . url ]  \n",
       "...                                                 ...  \n",
       "4995  [if aapl goes to over , i will go short. still...  \n",
       "4996  [mmm looks ready to break out. looking to go l...  \n",
       "4997  [amzn - closed over volume support inside of t...  \n",
       "4998  [bbt coiled up after finding support at / sma'...  \n",
       "4999  [jcp in oscillating range, oscillators say ove...  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stp words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'few', 'bottom', 'often', 'more', 'something', 'onto', 'hundred', 'then', 'always', 'â€˜re', 'the', 'put', 'our', 'because', 'front', 'how', 'empty', 'themselves', 'i', 'enough', 'done', 'even', 'could', 'beside', 'under', 'serious', 'well', 'nor', 'we', 'first', 'her', 'whole', 'already', 'two', 'whereupon', 'call', 'were', 'all', 'nobody', 'side', 'toward', 'sometime', 'â€™d', 'but', 'not', 'against', 'hers', 'ever', 'any', 'it', 'less', 'herein', 'should', 'on', 'be', 'give', 'who', \"'ll\", 'whereby', 'twelve', 'you', 'whatever', 'forty', 'beforehand', 'anywhere', 'only', 'from', 'ours', 'thence', 'hereupon', 'moreover', 'must', 'various', 'some', 'third', 'regarding', 'per', 'a', \"'re\", 'them', 'really', 'almost', 'â€˜ll', 'just', 'namely', 'â€™ve', 'other', 'yours', 'such', 'after', 'mine', 'there', 'however', 'where', 'â€˜ve', 'why', 'either', 'meanwhile', 'â€™ll', 'along', 'are', 'does', 'â€™m', 'amount', 'while', 'someone', 'towards', 'thereupon', 'else', 'whoever', 'wherein', 'in', 'and', 'doing', 'beyond', 'ten', 'whither', 'yourselves', 'do', 'three', 'formerly', 'before', 'thereby', 'becomes', 'was', 'hereby', 'alone', 'herself', 'latterly', 'everyone', 'move', 'once', 'or', 'us', 'many', 'since', 'get', 'much', 'above', 'nâ€˜t', 'due', 'so', 'of', 'during', 'unless', 'an', \"'s\", 'can', 'nevertheless', 'anything', 'fifteen', 'yet', 'â€˜d', 'everything', 'therein', 'every', 'anyhow', 'their', 'never', 'nowhere', 'until', 'when', 'off', 'by', 'about', 'between', 'within', 'seems', 'up', 'now', 'twenty', 'through', 'hereafter', 'top', 'that', 'without', 'being', 'whom', 'here', 'together', 'nothing', 'at', 're', 'used', 'seem', 'become', 'last', 'whereafter', 'his', 'those', 'keep', 'might', 'have', 'she', 'neither', 'he', \"n't\", 'six', 'thereafter', 'these', 'each', 'cannot', 'would', 'somehow', 'sometimes', 'into', 'behind', 'they', 'whether', 'me', 'nine', 'show', 'go', 'anyway', 'full', \"'d\", 'myself', 'seemed', 'will', 'former', 'several', 'which', 'own', 'down', 'over', 'ca', 'this', 'next', 'as', 'though', 'whence', 'anyone', 'say', 'mostly', 'besides', 'using', 'fifty', 'therefore', 'one', 'across', 'yourself', 'is', 'further', 'most', 'both', 'whose', 'may', 'upon', 'has', 'amongst', 'another', 'rather', 'least', 'otherwise', 'again', \"'ve\", 'no', 'him', 'if', 'thru', 'quite', 'whereas', 'still', 'â€˜s', 'perhaps', 'seeming', 'thus', 'becoming', 'ourselves', 'via', 'around', 'been', 'back', 'became', 'make', 'wherever', 'to', 'had', 'five', 'except', 'eleven', 'part', 'elsewhere', 'see', 'my', 'indeed', 'itself', 'throughout', 'its', 'out', 'among', 'hence', 'none', 'nâ€™t', 'below', 'also', 'everywhere', 'â€™re', 'â€˜m', 'than', 'whenever', 'please', 'eight', 'did', 'for', 'name', 'same', 'four', 'made', 'take', 'although', 'others', 'somewhere', 'very', 'noone', 'latter', 'â€™s', 'your', 'what', \"'m\", 'with', 'himself', 'sixty', 'too', 'am', 'afterwards'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords[0:300]=['whereupon', 'nâ€˜t', 'whoever', 'ca', 'serious', 'seemed', 'been', 'few', 'which', 'there', 'myself', 'part', 'seeming', 'indeed', 'call', 'another', 'namely', 'show', 'used', 'for', 'sometime', 'wherever', 'bottom', 'ever', 'fifteen', 'ten', 'top', 'done', 'noone', 'not', 'yourself', 'beyond', 'afterwards', 'move', 'more', 'most', 'therein', 'back', \"'ve\", 'my', 'himself', 'â€˜ll', 'any', 'perhaps', 'something', 'last', 'until', 'anyhow', 'nobody', 'our', 'hereby', 're', 'hers', 'does', 'put', 'every', 'into', 'such', 'they', 'everywhere', 'one', 'always', 'has', 'full', 'anyway', 'third', 'us', 'it', 'towards', 'almost', 'on', 'out', 'her', 'as', 'might', 'same', 'your', 'me', 'hundred', 'together', 'the', 'already', 'an', 'eight', 'mostly', 'have', 'further', 'only', 'using', 'what', 'whereas', 'though', 'name', 'being', 'became', 'regarding', 'side', 'moreover', 'under', 'did', 'whether', 'amongst', 'that', 'whence', 'when', 'we', 'empty', 'well', 'herself', 'eleven', 'whither', 'say', 'him', 'even', 'off', 'against', 'give', 'below', 'beforehand', 'really', \"'ll\", 'itself', 'made', 'thus', 'toward', 'his', 'â€˜d', 'you', 'get', 'whole', 'a', 'would', 'ours', 'becomes', 'nevertheless', 'many', 'unless', 'throughout', 'either', 'over', 'these', 'and', 'so', 'them', 'â€™ll', 'those', 'since', 'somehow', 'â€™re', 'alone', 'neither', 'without', 'forty', 'cannot', 'make', 'he', 'twelve', 'front', 'in', 'none', 'down', 'after', 'was', 'thereupon', 'keep', 'around', 'go', 'however', 'no', 'becoming', 'yourselves', 'else', 'just', 'between', 'yet', 'whereby', 'â€™m', 'others', 'who', 'former', 'had', 'amount', 'among', 'everyone', 'herein', 'two', 'nor', 'other', 'could', 'thereafter', 'still', 'thereby', 'anyone', 'because', 'before', 'rather', 'will', 'hereafter', 'latterly', 'â€˜m', 'how', 'may', 'three', 'across', 'do', \"'m\", 'become', 'whom', 'up', 'along', 'each', 'due', 'sometimes', 'anything', 'within', 'is', 'several', 'should', 'latter', 'themselves', 'are', 'by', 'whereafter', 'she', 'someone', 'nothing', 'nowhere', 'behind', 'or', 'too', 'twenty', 'wherein', 'be', 'except', 'once', 'enough', 'besides', 'first', 'am', \"'s\", 'quite', 'anywhere', 'from', 'can', 'about', 'onto', 'â€™s', 'this', 'then', 'than', 'all', 'ourselves', 'at', 'while', 'also', 'â€˜re', 'if', 'five', 'upon', 'yours', 'least', 'very', 'although', 'where', 'less', 'above', 'nine', 'much', 'â€™d', 'hence', 'of', 'â€˜ve', 'whose', 'â€™ve', 'meanwhile', 'see', 'doing', 'per', 'elsewhere', 'their', 'mine', 'whatever', 'via', 'to', 'were', 'some', 'thence', 'various', 'â€˜s', 'here', 'why', 'please', 'thru', 'through', 'seems', 'take', 'again', 'during', 'seem', 'six', \"n't\", 'formerly', 'sixty', \"'re\", 'four', 'nâ€™t', 'but', 'everything', 'whenever', \"'d\", 'often', 'never', 'with', 'next', 'hereupon', 'otherwise', 'i', 'somewhere', 'both', 'beside', 'fifty', 'therefore', 'its', 'now', 'own', 'must']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(text):\n",
    "    removed_stopwords=[ i for i in text if i not in stopwords]\n",
    "    return removed_stopwords\n",
    "    \n",
    "stock['final_cleaned_text'] =stock['lemmatized_text'].apply(lambda x : stopword_removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                     final_cleaned_text  \n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...  \n",
       "1     [\"user: aapl movie. % return for the fear/gree...  \n",
       "2     [user i'd be afraid to short amzn - they are l...  \n",
       "3                                    [mnta over . url ]  \n",
       "4                                     [oi  over . url ]  \n",
       "...                                                 ...  \n",
       "4995  [if aapl goes to over , i will go short. still...  \n",
       "4996  [mmm looks ready to break out. looking to go l...  \n",
       "4997  [amzn - closed over volume support inside of t...  \n",
       "4998  [bbt coiled up after finding support at / sma'...  \n",
       "4999  [jcp in oscillating range, oscillators say ove...  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our final cleaned text is stock['final_cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Perform VADER (valence aware dictionary for sentiment reasoning) model for Sentiment Analysis on stock price twitter reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is a model that is used for sentiment analysis and is sensitive to polarity (positive /negative).\n",
    "It maps the lexical features to emotional intensities called sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid=SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any one review and check its score\n",
    "\n",
    "\n",
    "review1 = stock.iloc[2]['sentiment']\n",
    "review1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will now  calculate scores and compound scores for entire dataset by creating seperate columns and will compare our predictions with the given results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for adding sentiment scores \n",
    "\n",
    "stock['scores']= stock['sentiment'].apply(lambda review:sid.polarity_scores(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for adding compound scores \n",
    "\n",
    "stock['compound_score']=stock['scores'].apply(lambda dic:dic['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create condition on compound score to predict sentiment\n",
    "\n",
    "stock['predicted_sentiment'] =stock['compound_score'].apply(lambda x :'positive' if x>=0 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>[kickers on my watchlist xide trit soq pnk cpw...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>[\"user: aapl movie. % return for the fear/gree...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>[user i'd be afraid to short amzn - they are l...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>[mnta over . url ]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>[oi  over . url ]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>[if aapl goes to over , i will go short. still...</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>[mmm looks ready to break out. looking to go l...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>[amzn - closed over volume support inside of t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>[bbt coiled up after finding support at / sma'...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>[jcp in oscillating range, oscillators say ove...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                     tokenized_text  \\\n",
       "0     positive  [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     positive  [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     positive  [user i'd be afraid to short amzn - they are l...   \n",
       "3     positive                                 [mnta over . url ]   \n",
       "4     positive                                  [oi  over . url ]   \n",
       "...        ...                                                ...   \n",
       "4995  negative  [if aapl goes to over , i will go short. still...   \n",
       "4996  positive  [mmm looks ready to break out. looking to go l...   \n",
       "4997  positive  [amzn - closed over volume support inside of t...   \n",
       "4998  positive  [bbt coiled up after finding support at / sma'...   \n",
       "4999  positive  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                        lemmatized_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                     final_cleaned_text  \\\n",
       "0     [kickers on my watchlist xide trit soq pnk cpw...   \n",
       "1     [\"user: aapl movie. % return for the fear/gree...   \n",
       "2     [user i'd be afraid to short amzn - they are l...   \n",
       "3                                    [mnta over . url ]   \n",
       "4                                     [oi  over . url ]   \n",
       "...                                                 ...   \n",
       "4995  [if aapl goes to over , i will go short. still...   \n",
       "4996  [mmm looks ready to break out. looking to go l...   \n",
       "4997  [amzn - closed over volume support inside of t...   \n",
       "4998  [bbt coiled up after finding support at / sma'...   \n",
       "4999  [jcp in oscillating range, oscillators say ove...   \n",
       "\n",
       "                                                 scores  compound_score  \\\n",
       "0     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "1     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "2     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "3     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4     {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "...                                                 ...             ...   \n",
       "4995  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...         -0.5719   \n",
       "4996  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4997  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4998  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "4999  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.5574   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0               positive  \n",
       "1               positive  \n",
       "2               positive  \n",
       "3               positive  \n",
       "4               positive  \n",
       "...                  ...  \n",
       "4995            negative  \n",
       "4996            positive  \n",
       "4997            positive  \n",
       "4998            positive  \n",
       "4999            positive  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# compare given label with our predicted sentiment value\n",
    "\n",
    "print(accuracy_score(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 =accuracy_score(stock['sentiment'] ,stock['predicted_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00      1650\n",
      "    positive       1.00      1.00      1.00      3350\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1650    0]\n",
      " [   0 3350]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(stock['sentiment'] ,stock['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using different machine language algorithm we will try to predict sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=stock['final_cleaned_text']\n",
    "y=stock['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since stock['final_cleaned_text'] is in array of array , we need to convert into array of strings\n",
    "#Join all items in a tuple into a string\n",
    "\n",
    "stock['final_cleaned_text']=[\" \".join(i) for i in stock['final_cleaned_text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test ,y_train,y_test =train_test_split(x,y,test_size=0.25 ,random_state=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3305      come fly with me, let?s fly, let?s fly away  al\n",
       "4579    citi reiterates sell on bbry & tp of  - \"shock...\n",
       "1662                 has anyone shorted kerx? what price?\n",
       "2851    faz about to explode, get ready, bac just brok...\n",
       "192     gs jpm xlf hod, they are hungry for stocks out...\n",
       "                              ...                        \n",
       "3603     aapl strong if they keep buying into the close..\n",
       "4722    ma url major bearish divergence(now confirmed ...\n",
       "3340    stalking. rising channel on flir. if a pullbac...\n",
       "3064    xco . has technical support  min downside with...\n",
       "3398    amzn goog and crm move higher as the nq_f turn...\n",
       "Name: final_cleaned_text, Length: 3750, dtype: object"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4088    hca entering long, here's the daily, like the ...\n",
       "2080                             rjet entry . stop . url \n",
       "41      x out the / due to the move today and the kirb...\n",
       "796     red monthly triangle on cytx,....net profit  ,...\n",
       "354                                           mon - added\n",
       "                              ...                        \n",
       "2952    dakt short . /  break, ideal flat/trendless/re...\n",
       "757                     ampe,...sell short at .,  scaling\n",
       "3907                   cspi buying in new nano cap folio.\n",
       "1251    aapl head and shoulders pattern plays out, one...\n",
       "4188    f really looking good here, great call option ...\n",
       "Name: final_cleaned_text, Length: 1250, dtype: object"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a)  Use linear support vector machine along with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings(Inverse Document Frequency (IDF) is a weight indicating how commonly a word is used.The more frequent its usage across documents, the lower its score), and allow you to encode new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('Svm',LinearSVC())])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 =pipeline.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2 =accuracy_score(y_test,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.59      0.67       421\n",
      "    positive       0.81      0.90      0.86       829\n",
      "\n",
      "    accuracy                           0.80      1250\n",
      "   macro avg       0.79      0.75      0.76      1250\n",
      "weighted avg       0.80      0.80      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b) Using Logistic regression and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('logisticregression',LogisticRegression(penalty ='l2',solver ='saga'))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 =pipeline.predict(x_test)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3 =accuracy_score(y_test,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.44      0.57       421\n",
      "    positive       0.77      0.95      0.85       829\n",
      "\n",
      "    accuracy                           0.78      1250\n",
      "   macro avg       0.80      0.70      0.71      1250\n",
      "weighted avg       0.79      0.78      0.76      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c) Using Naive Bayes and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('naivebayes',MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3 =pipeline.predict(x_test)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4= accuracy_score(y_test,predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.21      0.34       421\n",
      "    positive       0.71      0.99      0.83       829\n",
      "\n",
      "    accuracy                           0.73      1250\n",
      "   macro avg       0.82      0.60      0.58      1250\n",
      "weighted avg       0.79      0.73      0.66      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d) Using Stochastic Gradiant Descent and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('SGD',SGDClassifier(loss = 'hinge', penalty = 'l2', random_state=0))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict4 =pipeline.predict(x_test)\n",
    "predict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy5= accuracy_score(y_test,predict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.61      0.66       421\n",
      "    positive       0.82      0.89      0.85       829\n",
      "\n",
      "    accuracy                           0.79      1250\n",
      "   macro avg       0.78      0.75      0.76      1250\n",
      "weighted avg       0.79      0.79      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e) Using Random Forest classifier and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('RFC', RandomForestClassifier(min_samples_split=4))])"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('RFC',RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,min_samples_split=4))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit =pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict5 =pipeline.predict(x_test)\n",
    "predict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy6= accuracy_score(y_test,predict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.51      0.62       421\n",
      "    positive       0.79      0.93      0.86       829\n",
      "\n",
      "    accuracy                           0.79      1250\n",
      "   macro avg       0.79      0.72      0.74      1250\n",
      "weighted avg       0.79      0.79      0.78      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performances of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD classifier</td>\n",
       "      <td>0.7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.7920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0                   VADER    1.0000\n",
       "1               LinearSVM    0.7992\n",
       "2     Logistic Regression    0.7792\n",
       "3             Naive Bayes    0.7280\n",
       "4          SGD classifier    0.7936\n",
       "5  RandomForestClassifier    0.7920"
      ]
     },
     "execution_count": 1081,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies =[accuracy1 ,accuracy2,accuracy3 ,accuracy4,accuracy5,accuracy6]\n",
    "models =['VADER','LinearSVM','Logistic Regression','Naive Bayes','SGD classifier','RandomForestClassifier']\n",
    "\n",
    "df =pd.DataFrame( {'Model':models ,'Accuracy': all_accuracies })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see RandomForest Classifier gives teh best result although SVM and SGD also gives nearly same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
