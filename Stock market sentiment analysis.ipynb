{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Stock market tweets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source :https://github.com/nunomroliveira/stock_market_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"@user: $AAPL MOVIE. 55% return for the FEAR/G...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>@user I'd be afraid to short $AMZN - they are ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>$MNTA Over $12.00 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>$OI  Over $21.37 URL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>If $AAPL goes to over $451, I will go short. S...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>$MMM looks ready to break out. Looking to go l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>$AMZN - Closed over volume support inside of t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>$BBT coiled up after finding support at 50/200...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>$JCP In oscillating range, oscillators say ove...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...   \n",
       "1     2013-01-01 20:33:37  \"@user: $AAPL MOVIE. 55% return for the FEAR/G...   \n",
       "2     2013-01-01 21:43:41  @user I'd be afraid to short $AMZN - they are ...   \n",
       "3     2013-01-02 01:49:48                             $MNTA Over $12.00 URL    \n",
       "4     2013-01-02 01:51:33                              $OI  Over $21.37 URL    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  If $AAPL goes to over $451, I will go short. S...   \n",
       "4996  2013-03-31 21:37:55  $MMM looks ready to break out. Looking to go l...   \n",
       "4997  2013-03-31 22:54:02  $AMZN - Closed over volume support inside of t...   \n",
       "4998  2013-03-31 23:22:15  $BBT coiled up after finding support at 50/200...   \n",
       "4999  2013-03-31 23:35:17  $JCP In oscillating range, oscillators say ove...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 1372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock =pd.read_csv(\"stock_tweets.csv\" ,encoding='unicode_escape',error_bad_lines=False)\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    3350\n",
       "negative    1650\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24f02c48ec8>"
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that negative class is almost 50 percent of postive class hence we shall not proceed with class balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning on text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    0\n",
       "text          0\n",
       "sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "stock.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean the text data\n",
    "# use re. sub() function which is used to replace occurrences of a particular sub-string with another sub-string.\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text =text.lower()                     # make in lower case\n",
    "    text = re.sub('\\[.*?@\\]','',text)      # remove text in square brackets\n",
    "    text =re.sub('\\n' ,'',text)\n",
    "    text = re.sub('\\w*\\d\\w*','' ,text)      # remove words containing numbers\n",
    "    text.lstrip(\"$\")                        # removes $ sign from start of string   \n",
    "    text.strip()\n",
    "    text =re.sub('[!@#$]','',text)          # replace given characters from string\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock['text'] = stock['text'].apply( lambda x:text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment  \n",
       "0     positive  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "...        ...  \n",
       "4995  negative  \n",
       "4996  positive  \n",
       "4997  positive  \n",
       "4998  positive  \n",
       "4999  positive  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Perform VADER (valence aware dictionary for sentiment reasoning) model for Sentiment Analysis on stock price twitter reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is a model that is used for sentiment analysis and is sensitive to polarity (positive /negative).\n",
    "It maps the lexical features to emotional intensities called sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid=SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 1380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any one review and check its score\n",
    "\n",
    "\n",
    "review1 = stock.iloc[2]['sentiment']\n",
    "review1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will now  calculate scores and compound scores for entire dataset by creating seperate columns and will compare our predictions with the given results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for adding sentiment scores \n",
    "\n",
    "stock['scores']= stock['sentiment'].apply(lambda review:sid.polarity_scores(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for adding compound scores \n",
    "\n",
    "stock['compound_score']=stock['scores'].apply(lambda dic:dic['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create condition on compound score to predict sentiment\n",
    "\n",
    "stock['predicted_sentiment'] =stock['compound_score'].apply(lambda x :'Positive' if x>=0 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 20:10:04</td>\n",
       "      <td>kickers on my watchlist xide trit soq pnk cpwr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 20:33:37</td>\n",
       "      <td>\"user: aapl movie. % return for the fear/greed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 21:43:41</td>\n",
       "      <td>user i'd be afraid to short amzn - they are lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02 01:49:48</td>\n",
       "      <td>mnta over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02 01:51:33</td>\n",
       "      <td>oi  over . url</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2013-03-31 21:35:26</td>\n",
       "      <td>if aapl goes to over , i will go short. still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2013-03-31 21:37:55</td>\n",
       "      <td>mmm looks ready to break out. looking to go lo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2013-03-31 22:54:02</td>\n",
       "      <td>amzn - closed over volume support inside of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2013-03-31 23:22:15</td>\n",
       "      <td>bbt coiled up after finding support at / sma's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2013-03-31 23:35:17</td>\n",
       "      <td>jcp in oscillating range, oscillators say over...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "0     2013-01-01 20:10:04  kickers on my watchlist xide trit soq pnk cpwr...   \n",
       "1     2013-01-01 20:33:37  \"user: aapl movie. % return for the fear/greed...   \n",
       "2     2013-01-01 21:43:41  user i'd be afraid to short amzn - they are lo...   \n",
       "3     2013-01-02 01:49:48                                   mnta over . url    \n",
       "4     2013-01-02 01:51:33                                    oi  over . url    \n",
       "...                   ...                                                ...   \n",
       "4995  2013-03-31 21:35:26  if aapl goes to over , i will go short. still ...   \n",
       "4996  2013-03-31 21:37:55  mmm looks ready to break out. looking to go lo...   \n",
       "4997  2013-03-31 22:54:02  amzn - closed over volume support inside of th...   \n",
       "4998  2013-03-31 23:22:15  bbt coiled up after finding support at / sma's...   \n",
       "4999  2013-03-31 23:35:17  jcp in oscillating range, oscillators say over...   \n",
       "\n",
       "     sentiment                                             scores  \\\n",
       "0     positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "1     positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "2     positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "3     positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "4     positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "...        ...                                                ...   \n",
       "4995  negative  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...   \n",
       "4996  positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "4997  positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "4998  positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "4999  positive  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...   \n",
       "\n",
       "      compound_score predicted_sentiment  \n",
       "0             0.5574            Positive  \n",
       "1             0.5574            Positive  \n",
       "2             0.5574            Positive  \n",
       "3             0.5574            Positive  \n",
       "4             0.5574            Positive  \n",
       "...              ...                 ...  \n",
       "4995         -0.5719            Negative  \n",
       "4996          0.5574            Positive  \n",
       "4997          0.5574            Positive  \n",
       "4998          0.5574            Positive  \n",
       "4999          0.5574            Positive  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4035\n"
     ]
    }
   ],
   "source": [
    "# compare given label with our predicted sentiment value\n",
    "\n",
    "print(accuracy_score(brexit['label'] ,brexit['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 =accuracy_score(brexit['label'] ,brexit['predicted_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.40      0.57      1990\n",
      "    Positive       0.01      1.00      0.02        10\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.50      0.70      0.29      2000\n",
      "weighted avg       1.00      0.40      0.57      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(brexit['label'] ,brexit['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 797 1193]\n",
      " [   0   10]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(brexit['label'] ,brexit['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using different machine language algorithm we will try to predict sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=stock['text']\n",
    "y=stock['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test ,y_train,y_test =train_test_split(x,y,test_size=0.25 ,random_state=40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a)  Use linear support vector machine along with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings(Inverse Document Frequency (IDF) is a weight indicating how commonly a word is used.The more frequent its usage across documents, the lower its score), and allow you to encode new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('Svm',LinearSVC())])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())])"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 =pipeline.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2 =accuracy_score(y_test,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.59      0.67       421\n",
      "    positive       0.81      0.90      0.86       829\n",
      "\n",
      "    accuracy                           0.80      1250\n",
      "   macro avg       0.79      0.75      0.76      1250\n",
      "weighted avg       0.80      0.80      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b) Using Logistic regression and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 1401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('logisticregression',LogisticRegression(penalty ='l2',solver ='saga'))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression(solver='saga'))])"
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 =pipeline.predict(x_test)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3 =accuracy_score(y_test,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.44      0.57       421\n",
      "    positive       0.77      0.95      0.85       829\n",
      "\n",
      "    accuracy                           0.78      1250\n",
      "   macro avg       0.80      0.70      0.71      1250\n",
      "weighted avg       0.79      0.78      0.76      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c) Using Naive Bayes and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 1408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('naivebayes',MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB())])"
      ]
     },
     "execution_count": 1409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 1410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3 =pipeline.predict(x_test)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4= accuracy_score(y_test,predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.21      0.34       421\n",
      "    positive       0.71      0.99      0.83       829\n",
      "\n",
      "    accuracy                           0.73      1250\n",
      "   macro avg       0.82      0.60      0.58      1250\n",
      "weighted avg       0.79      0.73      0.66      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d) Using Stochastic Gradiant Descent and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('SGD',SGDClassifier(loss = 'hinge', penalty = 'l2', random_state=0))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('SGD', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 1417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict4 =pipeline.predict(x_test)\n",
    "predict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy5= accuracy_score(y_test,predict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.61      0.66       421\n",
      "    positive       0.82      0.89      0.85       829\n",
      "\n",
      "    accuracy                           0.79      1250\n",
      "   macro avg       0.78      0.75      0.76      1250\n",
      "weighted avg       0.79      0.79      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e) Using Random Forest classifier and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('RFC', RandomForestClassifier(min_samples_split=4))])"
      ]
     },
     "execution_count": 1422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tfidf',TfidfVectorizer()),\n",
    "                   ('RFC',RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,min_samples_split=4))])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tfidf', TfidfVectorizer()),\n",
       "                ('RFC', RandomForestClassifier(min_samples_split=4))])"
      ]
     },
     "execution_count": 1423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'positive', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict5 =pipeline.predict(x_test)\n",
    "predict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy6= accuracy_score(y_test,predict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.54      0.65       421\n",
      "    positive       0.80      0.94      0.87       829\n",
      "\n",
      "    accuracy                           0.81      1250\n",
      "   macro avg       0.81      0.74      0.76      1250\n",
      "weighted avg       0.81      0.81      0.79      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performances of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>0.4035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD classifier</td>\n",
       "      <td>0.7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0                   VADER    0.4035\n",
       "1               LinearSVM    0.7992\n",
       "2     Logistic Regression    0.7792\n",
       "3             Naive Bayes    0.7280\n",
       "4          SGD classifier    0.7936\n",
       "5  RandomForestClassifier    0.8056"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies =[accuracy1 ,accuracy2,accuracy3 ,accuracy4,accuracy5,accuracy6]\n",
    "models =['VADER','LinearSVM','Logistic Regression','Naive Bayes','SGD classifier','RandomForestClassifier']\n",
    "\n",
    "df =pd.DataFrame( {'Model':models ,'Accuracy': all_accuracies })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see RandomForest Classifier gives teh best result although SVM and SGD also gives nearly same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
